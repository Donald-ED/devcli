# DevCLI

> **The Free, Local-First AI Coding Assistant**
> 
> Claude Code's powerful interface + Free open-source models = DevCLI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## ğŸŒŸ What is DevCLI?

DevCLI brings AI-powered coding assistance to everyone - **completely free and private**. Unlike cloud-based alternatives, DevCLI runs entirely on your machine using local models via [Ollama](https://ollama.ai).

**The Best of Both Worlds:**
- Claude Code's intuitive chat interface âœ¨
- 100% free open-source models ğŸ†“
- Complete privacy - never leaves your machine ğŸ”’

---

## âœ¨ Key Features

### ğŸ†“ **Completely Free**
No API costs, no subscriptions, no hidden fees. Use powerful models like DeepSeek, Llama, and Qwen without spending a dime.

### ğŸ”’ **Privacy First**
Your code never leaves your machine. No telemetry, no tracking, no cloud uploads.

### ğŸ’¬ **Interactive Chat Mode**
Just type `devcli` and start chatting - like Claude Code, but free!

### ğŸ¯ **Project-Aware**
Understands your entire codebase. Get answers with specific file names and line numbers.

### ğŸ¤– **Auto-Discovery**
Automatically finds and configures your Ollama models. No manual setup!

### ğŸ“Š **Three Output Modes**
- **Normal** - Beautiful, interactive
- **Quiet** - Clean, pipeable (`--quiet`)
- **JSON** - Structured, automatable (`--json`)

---

## ğŸš€ Quick Start

### Installation

```bash
# Install DevCLI
pip install devcli  # Coming to PyPI soon!

# Or install from source
git clone https://github.com/yourusername/devcli.git
cd devcli
pip install -e .
```

### Setup

```bash
# Install Ollama (if you haven't)
# Visit: https://ollama.ai

# Pull some models
ollama pull llama3.1
ollama pull deepseek-r1:7b

# Auto-discover models
devcli models-sync
```

### Start Chatting!

```bash
# Interactive mode (just type devcli!)
$ devcli

Welcome to DevCLI! ğŸ¤–
Model: llama3.1
Project context: âœ“ loaded

> what does this project do?
[AI explains your project...]

> where is the authentication code?
[AI provides specific file paths...]

> exit
Goodbye! ğŸ‘‹
```

---

## ğŸ“– Usage

### Interactive Mode (Recommended)

```bash
# Just type devcli to start chatting
devcli

# In-chat commands:
> /model deepseek-r1    # Switch models
> /nocontext           # Toggle project context
> /reset               # Clear history
> help                 # Show commands
> exit                 # Quit
```

### One-Shot Questions

```bash
# Normal mode
devcli ask "what does this project do?"

# With specific model
devcli ask "where is the auth logic?" --model deepseek-r1

# Without context (generic question)
devcli ask "explain async/await" --no-context
```

### Automation & Scripting

```bash
# Quiet mode - clean output for pipes
devcli ask "list all functions" --quiet | grep important

# JSON mode - structured data for scripts
devcli ask "analyze code" --json | jq '.response'

# Use in scripts
RESPONSE=$(devcli ask "check tests" --json | jq -r '.response')
echo "AI says: $RESPONSE"
```

### Project Understanding

```bash
# Scan your project
cd /path/to/your/project
devcli init

# Now ask context-aware questions
devcli ask "how does the config system work?"
# â†’ AI responds with specific file names and line numbers!
```

---

## ğŸ¯ Comparison

|  | DevCLI | Claudish | Claude Code | GitHub Copilot |
|---|:---:|:---:|:---:|:---:|
| **Cost** | ğŸ†“ Free | ğŸ’° API costs | ğŸ’° $20/month | ğŸ’° $10/month |
| **Privacy** | ğŸ”’ 100% local | â˜ï¸ Cloud | â˜ï¸ Cloud | â˜ï¸ Cloud |
| **Dependencies** | âœ… Standalone | âŒ Needs Claude Code | âœ… Standalone | âŒ Needs IDE |
| **Models** | ğŸ”“ Any Ollama model | ğŸ”“ OpenRouter | ğŸ”’ Anthropic only | ğŸ”’ OpenAI only |
| **Interactive Chat** | âœ… Built-in | âŒ Via Claude Code | âœ… Yes | âŒ No |
| **Project Context** | âœ… Custom scan | âœ… Via Claude Code | âœ… Yes | âš ï¸ Limited |
| **Offline** | âœ… Yes | âŒ No | âŒ No | âŒ No |
| **Auto-Discovery** | âœ… Yes | âŒ No | N/A | N/A |
| **JSON Output** | âœ… Yes | âœ… Yes | âŒ No | âŒ No |

---

## ğŸ“š Commands

### Core Commands

```bash
devcli                          # Interactive chat (default!)
devcli ask "question"           # One-shot question
devcli init                     # Scan project
devcli models-sync              # Auto-discover models
```

### Configuration

```bash
devcli config-show              # View settings
devcli config-set key value     # Update setting
devcli model-add name --provider ollama --model llama3.1
```

### Output Modes

```bash
devcli ask "question"           # Normal (beautiful)
devcli ask "question" --quiet   # Quiet (pipeable)
devcli ask "question" --json    # JSON (automatable)
```

See [COMMANDS.md](COMMANDS.md) for complete reference.

---

## ğŸ¨ Examples

### Example 1: Understand a New Codebase

```bash
$ cd unfamiliar-project/
$ devcli init
âœ“ Project initialized! 23 files scanned

$ devcli
> what does this project do?
[AI]: This is a REST API for task management built with FastAPI...

> where is the database connection code?
[AI]: The database connection is in `src/db/connection.py` lines 15-30...

> how does authentication work?
[AI]: Authentication uses JWT tokens. The logic is in:
      - `src/auth/jwt.py` (token generation)
      - `src/middleware/auth.py` (verification)
```

### Example 2: Automation

```bash
# Find all TODO comments
devcli ask "list all TODO comments" --quiet | grep -i urgent > urgent.txt

# Check test coverage
COVERAGE=$(devcli ask "analyze test coverage" --json | jq -r '.response')
if echo "$COVERAGE" | grep -q "low"; then
    echo "âš ï¸  Low test coverage detected!"
fi

# Generate documentation
for file in src/*.py; do
    devcli ask "document $file" --quiet >> DOCS.md
done
```

### Example 3: Multi-Model Comparison (Coming Soon)

```bash
# Try different models for the same task
devcli ask "optimize this function" --model llama3.1
devcli ask "optimize this function" --model deepseek-r1
devcli ask "optimize this function" --model qwen2.5

# Pick the best answer!
```

---

## ğŸ—ï¸ Architecture

```
devcli/
â”œâ”€â”€ cli.py              # Main CLI with Typer
â”œâ”€â”€ config.py           # Configuration management (Pydantic)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ scanner.py      # File scanning & filtering
â”‚   â””â”€â”€ context.py      # Project context building
â””â”€â”€ providers/
    â”œâ”€â”€ base.py         # Provider interface
    â””â”€â”€ ollama.py       # Ollama integration
```

**Tech Stack:**
- **CLI**: [Typer](https://typer.tiangolo.com/) - Modern CLI framework
- **UI**: [Rich](https://rich.readthedocs.io/) - Beautiful terminal output
- **Config**: [Pydantic](https://pydantic.dev/) - Type-safe configuration
- **Models**: [Ollama](https://ollama.ai) - Local LLM runtime

---

## ğŸ—ºï¸ Roadmap

### âœ… v0.1.0 - Foundation
- Project understanding & context
- Ollama integration
- Configuration system
- Auto-discovery

### âœ… v0.2.0 - Interactive
- Interactive chat mode
- Model switching
- Conversation history

### âœ… v0.3.0 - Polish (Current)
- JSON output mode
- Quiet mode
- Professional documentation
- MIT License

### ğŸš§ v0.4.0 - Advanced (Next)
- Status line (model/cost/context)
- Debug logging
- Token usage tracking
- Streaming responses

### ğŸ”® v0.5.0 - Power Features
- Code editing
- Model comparison
- OpenRouter integration
- RAG with embeddings

### ğŸ¯ v1.0.0 - Production
- PyPI release
- CI/CD pipeline
- Comprehensive tests
- 1000+ GitHub stars

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Ways to contribute:**
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ“– Improve documentation
- ğŸ”§ Submit pull requests
- â­ Star the repo!

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

**Inspired by:**
- [Claude Code](https://www.anthropic.com/claude-code) - Brilliant UX and agentic workflows
- [Claudish](https://github.com/MadAppGang/claudish) - JSON output and quiet mode ideas
- [Aider](https://github.com/paul-gauthier/aider) - Pioneering AI pair programming
- [Ollama](https://ollama.ai) - Making local LLMs accessible

**Built with:**
- [Typer](https://typer.tiangolo.com/) - CLI framework
- [Rich](https://rich.readthedocs.io/) - Terminal UI
- [Pydantic](https://pydantic.dev/) - Data validation

---

## ğŸŒŸ Star History

Star the repo to support development! â­

---

## ğŸ“ Support

- ğŸ“– [Documentation](COMMANDS.md)
- ğŸ› [Issues](https://github.com/yourusername/devcli/issues)
- ğŸ’¬ [Discussions](https://github.com/yourusername/devcli/discussions)
- ğŸ¦ [Twitter](https://twitter.com/yourusername)

---

<div align="center">

**Made with â¤ï¸ by developers, for developers**

[Get Started](SETUP.md) Â· [Documentation](COMMANDS.md) Â· [Contributing](CONTRIBUTING.md)

</div>
